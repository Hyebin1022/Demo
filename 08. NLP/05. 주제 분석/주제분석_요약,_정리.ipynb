{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **주제 분석(Topic Analysis)**"
      ],
      "metadata": {
        "id": "XAoTAfMO1c_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "주제 분석은 **텍스트 데이터**에서 **반복적으로 나타나는 단어 그룹이나 주제**를 추출하고 분석하는 자연어 처리(NLP)의 기술입니다. 다양한 비지도 학습 및 지도 학습 방법을 활용해 데이터를 요약하고 군집화합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## **1. 주제 분석의 개념과 목적**  \n",
        "\n",
        "### **1.1 주제(Topic)란?**  \n",
        "- **텍스트 데이터에서 반복적으로 나타나는 단어 그룹** 또는 **주제**를 의미합니다.  \n",
        "- **예시**:  \n",
        "   - 뉴스 기사 → \"경제\", \"스포츠\", \"정치\"  \n",
        "   - 고객 리뷰 → \"가격\", \"서비스 품질\", \"상품 기능\"\n",
        "\n",
        "### **1.2 목적**  \n",
        "- **숨겨진 구조 이해**: 텍스트 데이터에서 숨겨진 주제를 찾아내기.  \n",
        "- **문서 요약**: 방대한 텍스트를 요약해 주요 내용 파악.  \n",
        "- **유사 텍스트 군집화**: 비슷한 내용의 문서 그룹화.  \n",
        "- **정보 검색 개선**: 추천 시스템 및 검색 엔진 성능 개선.  \n",
        "\n",
        "---\n",
        "\n",
        "## **2. 주제 분석 유형**\n",
        "\n",
        "### **2.1 비지도 학습 기반 토픽 모델링**  \n",
        "- **정의**: 토픽을 자동으로 추출하는 방식입니다.  \n",
        "- **기술**:  \n",
        "   - **LSA (Latent Semantic Analysis)**: SVD(특이값 분해)를 기반으로 의미 추출  \n",
        "   - **LDA (Latent Dirichlet Allocation)**: 확률적 모델로 문서의 토픽 분포를 학습  \n",
        "\n",
        "### **2.2 지도 학습 기반 토픽 모델링**  \n",
        "- **정의**: 미리 정의된 주제나 레이블로 데이터를 분류하는 방식입니다.  \n",
        "- **기술**:  \n",
        "   - 머신러닝 및 딥러닝 모델 사용  \n",
        "\n",
        "---\n",
        "\n",
        "## **3. LSA (Latent Semantic Analysis)**  \n",
        "\n",
        "### **3.1 개념**  \n",
        "- **잠재 의미 분석**: 단어-문서 행렬을 SVD(특이값 분해)로 분해하여 의미를 추출하는 방법입니다.  \n",
        "- **핵심 아이디어**: 단어의 빈도뿐 아니라 **의미 기반**으로 문서를 재배치합니다.  \n",
        "\n",
        "---\n",
        "\n",
        "### **3.2 Truncated SVD를 활용한 주제 분석**  \n",
        "\n",
        "#### **단계별 과정**  \n",
        "\n",
        "1. **데이터 벡터화 (Bag-of-Words)**  \n",
        "   ```python\n",
        "   from sklearn.feature_extraction.text import CountVectorizer\n",
        "   vec = CountVectorizer(max_features=1000)\n",
        "   x_arr = vec.fit_transform([ \" \".join(tokens) for tokens in tokens_list ]).A\n",
        "   x_arr.shape\n",
        "   ```\n",
        "\n",
        "2. **SVD 적용**  \n",
        "   ```python\n",
        "   from sklearn.decomposition import TruncatedSVD\n",
        "   svd = TruncatedSVD(n_components=20, random_state=SEED)\n",
        "   u_arr = svd.fit_transform(x_arr)\n",
        "   ```\n",
        "\n",
        "3. **결과 확인**  \n",
        "   - **U 행렬**: 문서-주제 관계  \n",
        "   - **Σ (특이값)**: 주제의 중요도  \n",
        "   - **Vt 행렬**: 주제-단어 관계  \n",
        "\n",
        "4. **특이값 시각화 (엘보우 방법)**  \n",
        "   ```python\n",
        "   fig , ax = plt.subplots()\n",
        "   ax.plot( range(1,21), svd.singular_values_, marker=\"o\")\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## **4. LDA (Latent Dirichlet Allocation)**  \n",
        "\n",
        "### **4.1 개념**  \n",
        "- **잠재 디리클레 할당**: 문서가 여러 주제의 혼합으로 구성되며, 각 주제는 특정 단어 분포를 따른다고 가정하는 확률 모델입니다.  \n",
        "\n",
        "### **4.2 LDA 수행 과정**  \n",
        "1. **토픽 개수 \\( k \\) 설정**  \n",
        "2. **모든 단어를 주제에 랜덤하게 할당**  \n",
        "3. **문서와 주제의 확률 분포 계산**  \n",
        "4. **단어를 가장 높은 확률의 주제에 재할당**  \n",
        "5. **반복**  \n",
        "\n",
        "---\n",
        "\n",
        "### **4.3 Gensim으로 LDA 모델 학습**  \n",
        "\n",
        "#### **1. Dictionary 생성**  \n",
        "```python\n",
        "from gensim.corpora import Dictionary\n",
        "dic = Dictionary(tokens_list)\n",
        "dic.filter_extremes(no_below=10)\n",
        "```\n",
        "\n",
        "#### **2. Corpus 생성**  \n",
        "```python\n",
        "corpus = [ dic.doc2bow(tokens) for tokens in tokens_list ]\n",
        "```\n",
        "\n",
        "#### **3. LDA 모델 학습**  \n",
        "```python\n",
        "from gensim.models import LdaModel\n",
        "model = LdaModel(corpus=corpus, num_topics=8, id2word=dic, passes=10, random_state=SEED)\n",
        "```\n",
        "\n",
        "#### **4. 토픽별 상위 단어 확인**  \n",
        "```python\n",
        "model.print_topics(num_topics=8)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **5. 주제 다양도와 주제 응집도**  \n",
        "\n",
        "### **5.1 주제 다양도 (Topic Diversity)**  \n",
        "- **정의**: 토픽 간 단어 중복 정도를 평가  \n",
        "- **계산 방법**:  \n",
        "   $\n",
        "   \\text{다양도} = \\frac{\\text{합집합의 단어 수}}{\\text{주제 수} \\times \\text{상위 단어 수}}\n",
        "   $\n",
        "\n",
        "```python\n",
        "topn = 10\n",
        "s = set()\n",
        "for k in range(8):\n",
        "    arr = np.array(model.show_topic(k, topn))\n",
        "    s.update(arr[:,0])\n",
        "    \n",
        "score = len(s) / (8 * topn)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5.2 주제 응집도 (Topic Coherence)**  \n",
        "- **정의**: 각 토픽을 구성하는 단어들의 **연관성 정도**를 평가합니다.  \n",
        "- **0~1 사이의 값**이며, 1에 가까울수록 응집도가 높습니다.  \n",
        "\n",
        "```python\n",
        "from gensim.models import CoherenceModel\n",
        "coh = CoherenceModel(model=model, texts=tokens_list, dictionary=dic)\n",
        "coh.get_coherence()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **6. 문서별 주제 확률 분포**  \n",
        "\n",
        "### **벡터화된 주제 확률 생성**  \n",
        "```python\n",
        "df_lda = []\n",
        "for lst in model.get_document_topics(corpus):\n",
        "    lst = np.array(lst)\n",
        "    tmp = np.zeros(8)\n",
        "    idx = lst[:,0].astype(int)\n",
        "    tmp[idx] = lst[:,1]\n",
        "    df_lda.append(tmp)\n",
        "\n",
        "df_lda = pd.DataFrame(df_lda)\n",
        "```\n",
        "\n",
        "### **문서별 주요 주제 확인**  \n",
        "```python\n",
        "df_lda.idxmax(axis=1)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **7. LDA 시각화**\n",
        "\n",
        "### **pyLDAvis 활용**  \n",
        "LDA 모델의 결과를 시각화하여 주제 간 관계와 단어 분포를 확인합니다.  \n",
        "\n",
        "```python\n",
        "import pyLDAvis.gensim\n",
        "vis = pyLDAvis.gensim.prepare(model, corpus, dic)\n",
        "pyLDAvis.display(vis)\n",
        "```\n",
        "\n",
        "- **왼쪽 그래프**: 토픽 간 관계와 중요도 시각화  \n",
        "- **오른쪽 그래프**: 각 토픽의 주요 단어 분포 확인  \n",
        "\n",
        "---\n",
        "\n",
        "## **핵심 요약**  \n",
        "1. **주제 분석**은 텍스트 데이터에서 숨겨진 주제를 추출하는 기법입니다.  \n",
        "2. **LSA**와 **LDA**는 대표적인 토픽 모델링 기법입니다.  \n",
        "3. **주제 다양도**와 **주제 응집도**를 평가해 모델의 품질을 확인합니다.  \n",
        "4. **pyLDAvis**를 활용하면 LDA 결과를 직관적으로 시각화할 수 있습니다.  "
      ],
      "metadata": {
        "id": "LSIWmcl20sWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSA VS LDA"
      ],
      "metadata": {
        "id": "5aq_cnxC0sUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSA**와 **LDA**는 둘 다 텍스트 데이터에서 **숨겨진 주제(Topic)**를 찾기 위한 **주제 모델링 기법**\n",
        "하지만 **접근 방식**과 **결과 해석**에 차이가 있다.   \n",
        "\n",
        "---\n",
        "\n",
        "## **LSA (Latent Semantic Analysis): 의미 기반 주제 분석**  \n",
        "\n",
        "### **핵심 개념**  \n",
        "- **LSA**는 **수학적 방법(SVD, 특이값 분해)**을 사용해 텍스트에서 **단어의 의미**를 분석합니다.  \n",
        "- **문서-단어 행렬**을 분해해서 **의미의 숨겨진 차원(주제)**을 찾아냅니다.  \n",
        "\n",
        "---\n",
        "\n",
        "### **비유로 이해하기**  \n",
        "**LSA는 '성적표를 분석하는 방법'**과 비슷합니다.\n",
        "\n",
        "- **학생(문서)**과 **과목(단어)**의 성적표(빈도수)를 **행렬**이라고 생각해봅시다.  \n",
        "- 여기서 **성적표를 분석**하면, 학생들이 어떤 **숨겨진 능력(주제)**을 가지고 있는지를 찾아낼 수 있습니다.  \n",
        "\n",
        "#### 예시:  \n",
        "- 성적표에는 수학, 물리, 화학, 미술, 음악 점수가 있습니다.  \n",
        "- **LSA**를 사용하면 다음과 같은 숨겨진 주제(능력)를 찾아냅니다:  \n",
        "   - **주제 1: 이과형 능력** → 수학, 물리, 화학 점수에서 영향  \n",
        "   - **주제 2: 예체능형 능력** → 미술, 음악 점수에서 영향  \n",
        "\n",
        "이처럼 **LSA**는 \"문서-단어 행렬\"을 수학적으로 분해하여 숨겨진 주제를 찾아내지만, 단순히 **수학적 패턴**만을 보기 때문에 주제의 의미는 사용자가 해석해야 합니다.\n",
        "\n",
        "---\n",
        "\n",
        "### **장점**  \n",
        "- 계산이 비교적 간단하고 빠르다.  \n",
        "- 의미적으로 비슷한 단어를 **하나의 주제**로 묶어준다.  \n",
        "\n",
        "### **단점**  \n",
        "- 수학적 패턴만 사용하므로, **확률적 모델**에 비해 해석이 어렵다.  \n",
        "- 데이터에 **노이즈**가 많으면 결과가 왜곡될 수 있다.  \n",
        "\n",
        "---\n",
        "\n",
        "## **LDA (Latent Dirichlet Allocation): 확률 기반 주제 분석**  \n",
        "\n",
        "### **핵심 개념**  \n",
        "- **LDA**는 **확률 모델**을 사용해 문서가 **여러 주제의 혼합**으로 이루어져 있다고 가정합니다.  \n",
        "- 각 단어는 특정 주제에서 나올 **확률**에 따라 등장한다고 가정합니다.  \n",
        "\n",
        "---\n",
        "\n",
        "### **비유로 이해하기**  \n",
        "**LDA는 '요리의 레시피'**를 분석하는 방법과 비슷합니다.\n",
        "\n",
        "- 요리는 여러 **재료(단어)**가 섞여서 만들어집니다.  \n",
        "- **레시피(문서)**를 보고, 그 안에 어떤 **요리(주제)**가 숨어 있는지 확률적으로 분석합니다.  \n",
        "\n",
        "#### 예시:  \n",
        "- **요리 1: 스파게티** → 재료: 면(70%), 토마토(20%), 치즈(10%)  \n",
        "- **요리 2: 샐러드** → 재료: 채소(60%), 드레싱(30%), 치즈(10%)  \n",
        "- **레시피 1**에서 **면, 토마토, 채소**가 등장한다면, LDA는 다음과 같이 확률적으로 추정합니다:  \n",
        "   - **스파게티(70%)**, **샐러드(30%)**  \n",
        "\n",
        "이처럼 **LDA**는 문서가 여러 주제로 이루어졌다고 가정하고, 주제와 단어의 **확률 분포**를 학습합니다.  \n",
        "\n",
        "---\n",
        "\n",
        "### **장점**  \n",
        "- 확률 모델을 기반으로 하므로 결과가 더 해석 가능하고 신뢰도가 높다.  \n",
        "- 문서가 **여러 주제의 혼합**으로 구성될 수 있음을 고려한다.  \n",
        "\n",
        "### **단점**  \n",
        "- 계산이 LSA보다 복잡하고 시간이 오래 걸린다.  \n",
        "- 주제 개수(토픽 수)를 **사전에 설정**해야 한다.  \n",
        "\n",
        "---\n",
        "\n",
        "## **LSA vs LDA의 차이점 요약**\n",
        "\n",
        "| **구분**               | **LSA**                                | **LDA**                                |\n",
        "|------------------------|---------------------------------------|---------------------------------------|\n",
        "| **접근 방식**          | **수학적 분해 (SVD)**                 | **확률 모델**                         |\n",
        "| **숨겨진 주제**        | 수학적 패턴에 의해 결정됨             | 단어의 확률 분포를 기반으로 결정됨     |\n",
        "| **해석 가능성**        | 해석이 어렵고 주제의 의미가 불분명함   | 주제와 단어 확률을 통해 해석이 명확함 |\n",
        "| **문서와 주제의 관계** | 문서는 **하나의 주제**로 압축됨         | 문서는 **여러 주제의 혼합**으로 표현됨 |\n",
        "| **계산 복잡도**        | 비교적 간단하고 빠름                  | 계산이 복잡하고 시간이 더 걸림         |\n",
        "\n",
        "---\n",
        "\n",
        "## **간단한 예시 비교**\n",
        "\n",
        "| **문서**                     | **LSA 결과**                       | **LDA 결과**                           |\n",
        "|-----------------------------|----------------------------------|--------------------------------------|\n",
        "| \"강아지, 고양이, 귀엽다\"     | 주제 1: **반려동물**                | 주제 1: **반려동물(70%)**, 주제 2: **감정(30%)** |\n",
        "| \"가격, 품질, 배송이 좋다\"     | 주제 2: **상품 리뷰**               | 주제 3: **품질(50%)**, 주제 4: **배송(50%)**   |\n",
        "\n",
        "**해석**:  \n",
        "- **LSA**는 문서를 **단일 주제**로 분류하는 느낌입니다.  \n",
        "- **LDA**는 문서가 여러 주제의 **혼합**임을 고려하여 확률적으로 표현합니다.  \n",
        "\n",
        "---\n",
        "\n",
        "## **결론: 언제 LSA와 LDA를 사용할까?**  \n",
        "\n",
        "1. **빠르게 주제를 분석하고 싶다면 → LSA**  \n",
        "   - 계산이 간단하고 빠르므로 초기 분석에 적합합니다.  \n",
        "\n",
        "2. **더 정확하고 해석 가능한 결과를 원한다면 → LDA**  \n",
        "   - 확률적 모델을 사용하므로 주제의 의미가 명확하고 결과가 신뢰할 수 있습니다.  \n",
        "\n",
        "---\n",
        "\n",
        "이처럼 LSA는 **수학적 분해**를 통해 숨겨진 주제를 찾는 반면, LDA는 **확률적 모델**을 통해 더 직관적이고 해석 가능한 주제를 찾아낸다."
      ],
      "metadata": {
        "id": "ZdYCI4Ri1Y4y"
      }
    }
  ]
}